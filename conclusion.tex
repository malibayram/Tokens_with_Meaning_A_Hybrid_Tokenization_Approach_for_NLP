\section{Conclusion}
\label{sec:conclusion}

In this study, we introduced a linguistically informed hybrid tokenization framework designed to address the challenges of morphologically rich languages. By integrating rule-based morphological analysis with BPE, our approach preserves morpheme boundaries and minimizes vocabulary redundancy. Empirical evaluations on the TR-MMLU dataset demonstrate that our tokenizer achieves significantly higher linguistic alignment (90.29\% TR~\%, 85.80\% Pure~\%) compared to state-of-the-art multilingual models like LLaMA, Gemma, and Qwen. These results validate that incorporating linguistic structure into tokenization yields more semantically coherent representations.

\subsection{Limitations}
While our results are promising, this study has several limitations. First, our evaluation relies primarily on intrinsic metrics (TR~\% and Pure~\%). Due to computational constraints, we did not pretrain a language model from scratch to empirically verify the impact of our tokenizer on downstream task performance (e.g., perplexity, classification accuracy). Establishing a causal link between token purity and model performance remains a critical next step. Second, our current implementation is in Python, which may not match the inference speed of highly optimized Rust-based tokenizers used in production LLMs. We have not yet conducted rigorous benchmarking of processing time or memory usage. Third, the approach relies on manually curated dictionaries, which may require maintenance to cover evolving language use and neologisms.

\subsection{Future Work}
Future research will focus on three key areas: (1) \textbf{Downstream Evaluation:} Training a small-scale language model (e.g., 100M parameters) using our tokenizer to measure improvements in perplexity and task-specific accuracy compared to standard BPE; (2) \textbf{Optimization:} Re-implementing the tokenizer in Rust to ensure it meets the latency requirements of real-time applications; and (3) \textbf{Generalization:} Extending the framework to other agglutinative languages such as Finnish and Hungarian to test the cross-linguistic validity of our hybrid approach.